# -*- coding: utf-8 -*-
"""Nm project coding.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NpgJHchZULN9CiFkaWuiUrU5eSKMR0-h
"""

# Install dependencies (if needed)
!pip install xgboost scikit-learn pandas matplotlib seaborn --quiet

# 1. Import Libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import xgboost as xgb

# 2. Sample Dataset (Replace with your own CSV in practice)
# For demo: create a synthetic air quality dataset
data = pd.DataFrame({
    'PM2.5': np.random.uniform(30, 200, 200),
    'NO2': np.random.uniform(10, 60, 200),
    'SO2': np.random.uniform(5, 30, 200),
    'CO': np.random.uniform(0.5, 3.0, 200),
    'AQI_Category': np.random.choice(['Good', 'Moderate', 'Unhealthy'], 200)
})

# 3. Encode the target variable
le = LabelEncoder()
data['AQI_Category'] = le.fit_transform(data['AQI_Category'])

# 4. Define features and target
X = data.drop('AQI_Category', axis=1)
y = data['AQI_Category']

# 5. Split into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 6. Train the XGBoost classifier
model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
model.fit(X_train, y_train)

# 7. Predict and evaluate
y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

# 8. Plot feature importance
xgb.plot_importance(model)
plt.title("Feature Importance")
plt.show()